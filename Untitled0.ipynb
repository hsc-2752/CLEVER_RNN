{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa/oQ5tXh1PT+Hr8mJbWaB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsc-2752/CLEVER_RNN/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUP9oLXEysNj",
        "outputId": "7da57fa7-2d58-4ab8-d34a-58a23a776ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq) (4.1.1)\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdiffeq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "SHJFBfR43PL-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                               transforms.Normalize(mean=[0.5],std=[0.5])])\n",
        "\n",
        "data_train = datasets.MNIST(root = \"./data/\",\n",
        "                            transform=transform,\n",
        "                            train = True,\n",
        "                            download = True)\n",
        "\n",
        "data_test = datasets.MNIST(root=\"./data/\",\n",
        "                           transform = transform,\n",
        "                           train = False)\n",
        "data_loader_train = torch.utils.data.DataLoader(dataset=data_train,\n",
        "                                                batch_size = 64,\n",
        "                                                shuffle = True,\n",
        "                                                 num_workers=2)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(dataset=data_test,\n",
        "                                               batch_size = 64,\n",
        "                                               shuffle = True,\n",
        "                                                num_workers=2)\n",
        "images, labels = next(iter(data_loader_train))\n",
        "img = torchvision.utils.make_grid(images)\n",
        "\n",
        "img = img.numpy().transpose(1,2,0)\n",
        "std = [0.5]\n",
        "mean = [0.5]\n",
        "img = img*std+mean\n",
        "#print([labels[i] for i in range(64)])\n",
        "#plt.imshow(img)"
      ],
      "metadata": {
        "id": "GarIxRVu3QqO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "     \"\"\"3x3 convolution with padding\"\"\"    \n",
        "     return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                      padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "def conv1x1(in_planes, out_planes, stride=1):    \n",
        "  \"\"\"1x1 convolution\"\"\"    \n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
      ],
      "metadata": {
        "id": "uVgDDwLSDYEU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Import the Adjoint Method (ODE Solver)\n",
        "from torchdiffeq import odeint_adjoint as odeint\n",
        "\n",
        "## Normal Residual Block Example\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "\n",
        "    #init a block - Convolve, pool, activate, repeat\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.norm1 = nn.BatchNorm2d(inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.norm2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "\n",
        "    #Forward pass - pass output of one layer to the input of the next \n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        out = self.relu(self.norm1(x))\n",
        "        out = self.conv1(out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        return out + shortcut\n",
        "\n",
        "## Ordinary Differential Equation Definition     \n",
        "\n",
        "class ODEfunc(nn.Module):\n",
        "\n",
        "    # init ODE variables\n",
        "    def __init__(self, dim):\n",
        "        super(ODEfunc, self).__init__()\n",
        "        self.norm1 = nn.BatchNorm2d(dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = conv3x3(dim, dim)\n",
        "        self.norm2 = nn.BatchNorm2d(dim)\n",
        "        self.conv2 = conv3x3(dim, dim)\n",
        "        self.norm3 = nn.BatchNorm2d(dim)\n",
        "        self.nfe = 0\n",
        "\n",
        "    # init ODE operations \n",
        "    def forward(self, t, x):\n",
        "      #nfe = number of function evaluations per timestep\n",
        "        self.nfe += 1\n",
        "        out = self.norm1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.norm3(out)\n",
        "        return out\n",
        "\n",
        "\n",
        " ## ODE block\n",
        "class ODEBlock(nn.Module):\n",
        "\n",
        "    #initialized as an ODE Function\n",
        "    #count the time\n",
        "    def __init__(self, odefunc):\n",
        "        super(ODEBlock, self).__init__()\n",
        "        self.odefunc = odefunc\n",
        "        self.integration_time = torch.tensor([0, 1]).float()\n",
        "\n",
        "    #foorward pass \n",
        "    #input the ODE function and input data into the ODE Solver (adjoint method)\n",
        "    # to compute a forward pass\n",
        "    def forward(self, x):\n",
        "        self.integration_time = self.integration_time.type_as(x)\n",
        "        out = odeint(self.odefunc, x, self.integration_time, rtol=1e-7, atol=1e-9)\n",
        "        return out[1]\n",
        "\n",
        "    @property\n",
        "    def nfe(self):\n",
        "        return self.odefunc.nfe\n",
        "\n",
        "    @nfe.setter\n",
        "    def nfe(self, value):\n",
        "        self.odefunc.nfe = value\n",
        "\n",
        "\n",
        "## Main Method\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    #Add Pooling\n",
        "    downsampling_layers = [\n",
        "         nn.Conv2d(1, 64, 3, 1),\n",
        "         ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n",
        "         ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n",
        "     ]\n",
        "\n",
        "    # Initialize the network as 1 ODE Block\n",
        "    feature_layers = [ODEBlock(ODEfunc(64))] \n",
        "    # Fully connected Layer at the end\n",
        "    fc_layers = [nn.BatchNorm2d(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(), nn.Linear(64, 10)]\n",
        "  \n",
        "    #The Model consists of an ODE Block, pooling, and a fully connected block at the end\n",
        "    #model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(torch.device)\n",
        "    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers)\n",
        "\n",
        "    #Declare Gradient Descent Optimizer\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "\n",
        "    n_epochs = 5\n",
        "    for epoch in range(n_epochs):\n",
        "      running_loss = 0.0\n",
        "      running_correct = 0\n",
        "      print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
        "      print(\"-\"*10)\n",
        "      for data in data_loader_train:\n",
        "          X_train, y_train = data\n",
        "          X_train, y_train = Variable(X_train), Variable(y_train)\n",
        "          outputs = model(X_train)\n",
        "          _,pred = torch.max(outputs.data, 1)\n",
        "          optimizer.zero_grad()\n",
        "          loss = nn.CrossEntropyLoss(outputs, y_train)\n",
        "          \n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.data[0]\n",
        "          running_correct += torch.sum(pred == y_train.data)\n",
        "      testing_correct = 0\n",
        "      for data in data_loader_test:\n",
        "          X_test, y_test = data\n",
        "          X_test, y_test = Variable(X_test), Variable(y_test)\n",
        "          outputs = model(X_test)\n",
        "          _, pred = torch.max(outputs.data, 1)\n",
        "          testing_correct += torch.sum(pred == y_test.data)\n",
        "      print(\"Loss is:{:.4f}, Train Accuracy is:{:.4f}%, Test Accuracy is:{:.4f}\".format(running_loss/len(data_train),\n",
        "                                                                                        100*running_correct/len(data_train),\n",
        "                                                                                        100*testing_correct/len(data_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YNtnB5scyxIF",
        "outputId": "14436a11-8d5b-4881-f8c5-97dd1614a0f6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-377611638c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    115\u001b[0m           \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m           \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-377611638c62>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m## Ordinary Differential Equation Definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (13) must match the size of tensor b (26) at non-singleton dimension 3"
          ]
        }
      ]
    }
  ]
}